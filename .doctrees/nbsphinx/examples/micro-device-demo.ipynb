{
 "cells": [
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "6f88ba99",
   "metadata": {},
   "source": [
    "# Using the NengoEdge Micro Runner\n",
    "\n",
    "In this example we will walk through loading and running a model exported from\n",
    "NengoEdge\n",
    "that's been uniquely configured to run on micro devices supporting TFLite Micro\n",
    "(we support the STM32F746 Discovery Board (Disco) and nRF52840 Dev Board\n",
    "(Nordic)). The goal\n",
    "of this demo is to provide a template for you to make your own custom\n",
    "applications using\n",
    "the NengoEdge runner."
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "bea010a9",
   "metadata": {},
   "source": [
    "## Installation\n",
    "\n",
    "First, install NengoEdge tools using\n",
    "[these instructions](https://www.nengo.ai/nengo-edge/developers.html).\n",
    "Feel free to skip the Tensorflow step since we won't need it for this\n",
    "runner.\n",
    "\n",
    "For the micro device example, it's assumed that you have completed the\n",
    "installation steps for either your Disco or Nordic board,\n",
    "\n",
    "- [Nordic guide\n",
    "](https://www.nordicsemi.com/Products/Development-software/nrf-connect-sdk)\n",
    "- [Disco guide\n",
    "](https://wiki.st.com/stm32mcu/wiki/Microcontroller)\n",
    "\n",
    "Take note of the **serial** and **drive** paths that are associated with your\n",
    "micro device as these are **required** for the Python runner. For example,\n",
    "the STM Discovery Board should generate serial and drive paths on your\n",
    "system named something like `/dev/ttyACM0`\n",
    "and `/media/<username>/DIS_F746NG` respectively (exact names will depend on\n",
    "your system)."
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "38218e2a",
   "metadata": {},
   "source": [
    "## Train a model in NengoEdge\n",
    "\n",
    "The first step is to train a model in NengoEdge for your desired hardware. See\n",
    "[this blog post\n",
    "](https://appliedbrainresearch.com/blog/fast-keyword-detection-with-lmus-on-gpu)\n",
    "for a detailed walkthrough on how to train such a model.\n",
    "\n",
    "## Export the trained model\n",
    "\n",
    "When exporting the model from NengoEdge you must choose the \"BINARY\" option to get a\n",
    "model targeted to run on microcontroller devices that use TFLiteMicro. The downloaded\n",
    "artifacts can be unpacked to a directory of your choice, and for the purpose of this\n",
    "demo we'll assume the contents have been unpacked to a directory called `micro_demo/`.\n",
    "\n",
    "Inside this directory you'll find two files (note: the binary file extension may change\n",
    "depending on the specific device):\n",
    "\n",
    "- `nengoedge_project.bin`\n",
    "- `parameters.json`\n",
    "\n",
    "We'll create a `DiscoRunner` that utilizes these artifacts.\n",
    "\n",
    "Note that if you are running this code locally, you will need to uncomment the\n",
    "`os.environ` lines and update `<DISCO_SERIAL_PATH>`/`<DISCO_DRIVE_PATH>` to point to\n",
    "the serial/drive path (see the Installation steps above)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "879ba6a2",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-04-29T18:03:35.992640Z",
     "iopub.status.busy": "2024-04-29T18:03:35.992404Z",
     "iopub.status.idle": "2024-04-29T18:03:47.633570Z",
     "shell.execute_reply": "2024-04-29T18:03:47.632986Z"
    }
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024-04-29 18:03:36.347570: I tensorflow/tsl/cuda/cudart_stub.cc:28] Could not find cuda drivers on your machine, GPU will not be used.\n",
      "2024-04-29 18:03:36.369605: I tensorflow/tsl/cuda/cudart_stub.cc:28] Could not find cuda drivers on your machine, GPU will not be used.\n",
      "2024-04-29 18:03:36.370044: I tensorflow/core/platform/cpu_feature_guard.cc:182] This TensorFlow binary is optimized to use available CPU instructions in performance-critical operations.\n",
      "To enable the following instructions: AVX2 FMA, in other operations, rebuild TensorFlow with the appropriate compiler flags.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024-04-29 18:03:36.786650: W tensorflow/compiler/tf2tensorrt/utils/py_utils.cc:38] TF-TRT Warning: Could not find TensorRT\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "f447d1b2d5a9402f87bba606c7f9885f",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Output()"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/runner/_work/nengo-edge/nengo-edge/nengo-edge/nengo_edge/config.py:37: UserWarning: Downloaded model uses nengo-edge 23.9.11.dev0, but you're using nengo-edge 24.3.6.dev0. Mismatch may cause errors.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"></pre>\n"
      ],
      "text/plain": []
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "import os\n",
    "import numpy as np\n",
    "\n",
    "from nengo_edge import DiscoRunner\n",
    "\n",
    "# os.environ[\"DISCO_SERIAL_PATH\"] = <DISCO_SERIAL_PATH>\n",
    "# os.environ[\"DISCO_DRIVE_PATH\"] = <DISCO_DRIVE_PATH>\n",
    "runner = DiscoRunner(\n",
    "    directory=\"micro_demo\",\n",
    "    serial_path=os.environ[\"DISCO_SERIAL_PATH\"],\n",
    "    device_path=os.environ[\"DISCO_DRIVE_PATH\"],\n",
    ")"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "3b77fde9",
   "metadata": {},
   "source": [
    "You will likely have particular audio inputs you are interested in identifying with the\n",
    "edge key word spotting model, but we'll showcase the general run steps assuming a random\n",
    "signal."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "10a42836",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-04-29T18:03:47.815011Z",
     "iopub.status.busy": "2024-04-29T18:03:47.814849Z",
     "iopub.status.idle": "2024-04-29T18:03:47.818001Z",
     "shell.execute_reply": "2024-04-29T18:03:47.817588Z"
    }
   },
   "outputs": [],
   "source": [
    "audio_inputs = np.random.uniform(\n",
    "    -1, 1, (1, runner.preprocessing[\"sample_rate\"])\n",
    ").astype(\"float32\")\n",
    "\n",
    "# Keyword labels for model outputs\n",
    "labels = [\n",
    "    \"<silence>\",\n",
    "    \"<unknown>\",\n",
    "    \"yes\",\n",
    "    \"no\",\n",
    "    \"up\",\n",
    "    \"down\",\n",
    "    \"left\",\n",
    "    \"right\",\n",
    "    \"on\",\n",
    "    \"off\",\n",
    "    \"stop\",\n",
    "    \"go\",\n",
    "]"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "f131ede6",
   "metadata": {},
   "source": [
    "And finally we can run the model using a microcontroller device,"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "19a21676",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-04-29T18:03:47.819850Z",
     "iopub.status.busy": "2024-04-29T18:03:47.819598Z",
     "iopub.status.idle": "2024-04-29T18:04:07.326357Z",
     "shell.execute_reply": "2024-04-29T18:04:07.325838Z"
    }
   },
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "e996810218fd483798eab4350ac696a9",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Output()"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"></pre>\n"
      ],
      "text/plain": []
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Predicted keyword: off\n"
     ]
    }
   ],
   "source": [
    "# using the runner's context opens the serial communication\n",
    "# to the board set by serial_path\n",
    "with runner:\n",
    "    outputs = runner.run(audio_inputs)\n",
    "    pred_label = np.argmax(outputs)\n",
    "    print(f\"Predicted keyword: {labels[pred_label]}\")"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "53be66c2",
   "metadata": {},
   "source": [
    "Since we used a random audio sample here and the model was trained on real audio\n",
    "samples, it's likely this particular classification will\n",
    "result in a random label. You'll notice that in this example we only ran the model\n",
    "on a single batch of inputs but the runner also supports batched inputs.\n",
    "\n",
    "That's it! You're now set to take this runner into your own applications."
   ]
  }
 ],
 "metadata": {
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.19"
  },
  "widgets": {
   "application/vnd.jupyter.widget-state+json": {
    "state": {
     "39150ee023804a5b919e7b56f72f8064": {
      "model_module": "@jupyter-widgets/base",
      "model_module_version": "2.0.0",
      "model_name": "LayoutModel",
      "state": {
       "_model_module": "@jupyter-widgets/base",
       "_model_module_version": "2.0.0",
       "_model_name": "LayoutModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/base",
       "_view_module_version": "2.0.0",
       "_view_name": "LayoutView",
       "align_content": null,
       "align_items": null,
       "align_self": null,
       "border_bottom": null,
       "border_left": null,
       "border_right": null,
       "border_top": null,
       "bottom": null,
       "display": null,
       "flex": null,
       "flex_flow": null,
       "grid_area": null,
       "grid_auto_columns": null,
       "grid_auto_flow": null,
       "grid_auto_rows": null,
       "grid_column": null,
       "grid_gap": null,
       "grid_row": null,
       "grid_template_areas": null,
       "grid_template_columns": null,
       "grid_template_rows": null,
       "height": null,
       "justify_content": null,
       "justify_items": null,
       "left": null,
       "margin": null,
       "max_height": null,
       "max_width": null,
       "min_height": null,
       "min_width": null,
       "object_fit": null,
       "object_position": null,
       "order": null,
       "overflow": null,
       "padding": null,
       "right": null,
       "top": null,
       "visibility": null,
       "width": null
      }
     },
     "78c0001b303248998b216f4a57d35806": {
      "model_module": "@jupyter-widgets/base",
      "model_module_version": "2.0.0",
      "model_name": "LayoutModel",
      "state": {
       "_model_module": "@jupyter-widgets/base",
       "_model_module_version": "2.0.0",
       "_model_name": "LayoutModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/base",
       "_view_module_version": "2.0.0",
       "_view_name": "LayoutView",
       "align_content": null,
       "align_items": null,
       "align_self": null,
       "border_bottom": null,
       "border_left": null,
       "border_right": null,
       "border_top": null,
       "bottom": null,
       "display": null,
       "flex": null,
       "flex_flow": null,
       "grid_area": null,
       "grid_auto_columns": null,
       "grid_auto_flow": null,
       "grid_auto_rows": null,
       "grid_column": null,
       "grid_gap": null,
       "grid_row": null,
       "grid_template_areas": null,
       "grid_template_columns": null,
       "grid_template_rows": null,
       "height": null,
       "justify_content": null,
       "justify_items": null,
       "left": null,
       "margin": null,
       "max_height": null,
       "max_width": null,
       "min_height": null,
       "min_width": null,
       "object_fit": null,
       "object_position": null,
       "order": null,
       "overflow": null,
       "padding": null,
       "right": null,
       "top": null,
       "visibility": null,
       "width": null
      }
     },
     "e996810218fd483798eab4350ac696a9": {
      "model_module": "@jupyter-widgets/output",
      "model_module_version": "1.0.0",
      "model_name": "OutputModel",
      "state": {
       "_dom_classes": [],
       "_model_module": "@jupyter-widgets/output",
       "_model_module_version": "1.0.0",
       "_model_name": "OutputModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/output",
       "_view_module_version": "1.0.0",
       "_view_name": "OutputView",
       "layout": "IPY_MODEL_78c0001b303248998b216f4a57d35806",
       "msg_id": "",
       "outputs": [
        {
         "data": {
          "text/html": "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">Running inference on device <span style=\"color: #f92672; text-decoration-color: #f92672\">━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━</span><span style=\"color: #3a3a3a; text-decoration-color: #3a3a3a\">╺</span> <span style=\"color: #800080; text-decoration-color: #800080\"> 98%</span> <span style=\"color: #008080; text-decoration-color: #008080\">0:00:01</span>\n</pre>\n",
          "text/plain": "Running inference on device \u001b[38;2;249;38;114m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[38;5;237m╺\u001b[0m \u001b[35m 98%\u001b[0m \u001b[36m0:00:01\u001b[0m\n"
         },
         "metadata": {},
         "output_type": "display_data"
        }
       ],
       "tabbable": null,
       "tooltip": null
      }
     },
     "f447d1b2d5a9402f87bba606c7f9885f": {
      "model_module": "@jupyter-widgets/output",
      "model_module_version": "1.0.0",
      "model_name": "OutputModel",
      "state": {
       "_dom_classes": [],
       "_model_module": "@jupyter-widgets/output",
       "_model_module_version": "1.0.0",
       "_model_name": "OutputModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/output",
       "_view_module_version": "1.0.0",
       "_view_name": "OutputView",
       "layout": "IPY_MODEL_39150ee023804a5b919e7b56f72f8064",
       "msg_id": "",
       "outputs": [
        {
         "data": {
          "text/html": "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">Flashing binary to device <span style=\"color: #729c1f; text-decoration-color: #729c1f\">━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━</span> <span style=\"color: #800080; text-decoration-color: #800080\">100%</span> <span style=\"color: #808000; text-decoration-color: #808000\">0:00:10</span>\n</pre>\n",
          "text/plain": "Flashing binary to device \u001b[38;2;114;156;31m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[35m100%\u001b[0m \u001b[33m0:00:10\u001b[0m\n"
         },
         "metadata": {},
         "output_type": "display_data"
        }
       ],
       "tabbable": null,
       "tooltip": null
      }
     }
    },
    "version_major": 2,
    "version_minor": 0
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
